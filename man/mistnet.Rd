% Generated by roxygen2 (4.0.1): do not edit by hand
\name{mistnet}
\alias{mistnet}
\title{Construct a mistnet model}
\usage{
mistnet(x, y, layer.definitions, loss, updater = adagrad.updater(learning.rate
  = 0.01), sampler = gaussianSampler(ncol = 10, sd = 1),
  n.importance.samples = 30, n.minibatch = 10, training.iterations = 0)
}
\arguments{
\item{x}{a \code{numeric} \code{matrix} of predictor variables.  One row
per example, one column per predictive feature.}

\item{y}{a \code{matrix} of responses to \code{x}.  One row per example, one
column per response variable.}

\item{layer.definitions}{a \code{list} of specifications for each layer in
the network, as produced by \code{defineLayer}.}

\item{loss}{a \code{loss} object, defining the function for optimization to
minimize, as well as its gradient}

\item{updater}{an \code{updater} object, specifying how the model should move
across the likelihood surface (e.g. stochastic gradient descent or adagrad)}

\item{sampler}{a \code{sampler} object, specifying the distribution of the
latent variables}

\item{n.importance.samples}{an \code{integer}. More samples will take more time
to compute, but will provide a more precise estimate of the likelihood gradient.}

\item{n.minibatch}{an \code{integer} specifying the number of rows to include
in each stochastic estimate of the likelihood gradient.}

\item{training.iterations}{an \code{integer} number of minibatches to process
before terminating. Currently, it is best practice to leave this value at 0
and manually initialize the model's coefficients before beginning training}
}
\description{
This function creates a \code{network} object for fitting a mistnet model.
}
\examples{
# 107 rows of fake data
x = matrix(rnorm(1819), ncol = 17, nrow = 107)
y = dropoutMask(107, 14)

# Create the network object
net = mistnet(
  x = x,
  y = y,
  layer.definitions = list(
    defineLayer(
      nonlinearity = rectify.nonlinearity(),
      size = 30,
      prior = gaussianPrior(0, 0.01)
    ),
    defineLayer(
      nonlinearity = rectify.nonlinearity(),
      size = 12,
      prior = gaussianPrior(0, 0.01)
    ),
    defineLayer(
      nonlinearity = sigmoid.nonlinearity(),
      size = ncol(y),
      prior = gaussianPrior(0, 0.01)
    )
  ),
  loss = bernoulliLoss(),
  updater = adagrad.updater(learning.rate = .01),
  sampler = gaussianSampler(ncol = 10, sd = 1),
  n.importance.samples = 30,
  n.minibatch = 10,
  training.iterations = 0
)

# Currently, mistnet does not initialize the coefficients automatically.
# This gets it started with nonzero values.
for(layer in net$layers){
  layer$coefficients[ , ] = rnorm(length(layer$coefficients), sd = .01)
}

# Fit the model
net$fit(iterations = 10)
}
\seealso{
\code{\link{network}}
}


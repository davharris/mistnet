% Generated by roxygen2 (4.0.1): do not edit by hand
\name{mistnet}
\alias{mistnet}
\title{Construct a mistnet model}
\usage{
mistnet(x, y, layer.definitions, loss, updater,
  sampler = gaussian.sampler(ncol = 10L, sd = 1), n.importance.samples = 25,
  n.minibatch = 25, training.iterations = 0, shuffle = TRUE,
  initialize.biases = TRUE, initialize.weights = TRUE)
}
\arguments{
\item{x}{a \code{numeric} \code{matrix} of predictor variables.  One row per
record, one column per predictive feature.}

\item{y}{a \code{matrix} of responses to \code{x}.  One row per record, one
column per response variable.}

\item{layer.definitions}{a \code{list} of specifications for each layer in
the network, as produced by \code{\link{defineLayer}}.}

\item{loss}{a \code{\link{loss}} object, defining the function for
optimization to minimize, as well as its gradient.}

\item{updater}{an \code{\link{updater}} object, specifying how the model
should move across the likelihood surface (e.g. stochastic gradient descent
or adagrad)}

\item{sampler}{a \code{\link{sampler}} object, specifying the distribution of
the latent variables}

\item{n.importance.samples}{an \code{integer}. More samples will take more
time to compute, but will provide a more precise estimate of the likelihood
gradient.}

\item{n.minibatch}{an \code{integer} specifying the number of rows to include
in each stochastic estimate of the likelihood gradient.}

\item{training.iterations}{an \code{integer} number of minibatches to process
before terminating. Defaults to zero so that the user can adjust the
network before training begins.}

\item{shuffle}{logical.  Should the data be shuffled after each epoch?
Defaults to TRUE.}

\item{initialize.biases}{logical.  Should the network's final layer's biases
be initialized to nonzero values? Initial values depend on the
\code{\link{nonlinearity}} of the final layer.}

\item{initialize.weights}{logical.  Should the weights in each layer be
initialized automatically? If \code{TRUE}, each layer's weights will be
sampled randomly from their \code{\link{prior}}s.}
}
\description{
This function creates a \code{network} object for fitting a mistnet model.
}
\examples{
# 107 rows of fake data
x = matrix(rnorm(1819), nrow = 107, ncol = 17)
y = dropoutMask(107, 14)

# Create the network object
net = mistnet(
  x = x,
  y = y,
  layer.definitions = list(
    defineLayer(
      nonlinearity = rectify.nonlinearity(),
      size = 30,
      prior = gaussian.prior(mean = 0, sd = 0.1)
    ),
    defineLayer(
      nonlinearity = rectify.nonlinearity(),
      size = 12,
      prior = gaussian.prior(mean = 0, sd = 0.1)
    ),
    defineLayer(
      nonlinearity = sigmoid.nonlinearity(),
      size = ncol(y),
      prior = gaussian.prior(mean = 0, sd = 0.1)
    )
  ),
  loss = bernoulliLoss(),
  updater = adagrad.updater(learning.rate = .01),
  sampler = gaussian.sampler(ncol = 10L, sd = 1),
  n.importance.samples = 30,
  n.minibatch = 10,
  training.iterations = 0
)

# Fit the model
net$fit(iterations = 10)
}
\seealso{
\code{\link{network}}
}


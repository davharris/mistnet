% Generated by roxygen2 (4.0.0): do not edit by hand
\docType{class}
\name{layer-class}
\alias{layer}
\alias{layer-class}
\title{Layer}
\description{
A reference class object for one layer of computation in a network object.
}
\details{
__
}
\section{Fields}{

\describe{
\item{\code{coef.dim}}{a length-two integer vector}

\item{\code{coefficients}}{a matrix of real numbers}

\item{\code{biases}}{a numeric vector}

\item{\code{nonlinearity}}{a \code{nonlinearity} object}

\item{\code{prior}}{a \code{prior} object}

\item{\code{inputs}}{a numeric array}

\item{\code{activations}}{a numeric array}

\item{\code{outputs}}{a numeric array}

\item{\code{error.grads}}{a numeric array}

\item{\code{weighted.bias.grads}}{a numeric vector}

\item{\code{weighted.llik.grads}}{a numeric matrix}

\item{\code{grad.step}}{a numeric matrix}
}}
\section{Methods}{

\describe{
\item{\code{backwardPass(incoming.error.grad, sample.num)}}{Calculate error.grads for one sample}

\item{\code{combineSampleGradients(weights, n.importance.samples)}}{update weighted.llik.grads and weighted.bias.grads based on importance 
weights and gradients from backpropagation}

\item{\code{forwardPass(input, sample.num)}}{Update inputs, activations, and outputs for one sample}

\item{\code{resetState(minibatch.size, n.importance.samples)}}{Reset inputs, activations, outputs, error.grads, and grad.step to NA}

\item{\code{updateCoefficients(learning.rate, momentum, dataset.size, minibatch.size)}}{Calculate grad.step and add it to coefficients. Update biases}
}}


% Generated by roxygen2 (4.1.1): do not edit by hand
% Please edit documentation in R/loss.R
\docType{class}
\name{loss-class}
\alias{bernoulliLoss}
\alias{bernoulliLoss-class}
\alias{bernoulliRegLoss}
\alias{bernoulliRegLoss-class}
\alias{binomialLoss}
\alias{binomialLoss-class}
\alias{loss}
\alias{loss-class}
\alias{nbLoss}
\alias{nbLoss-class}
\alias{poissonLoss}
\alias{poissonLoss-class}
\alias{squaredLoss}
\alias{squaredLoss-class}
\title{Loss functions}
\arguments{
\item{a}{the \code{a} shape parameter in \code{\link{dbeta}}}

\item{b}{the \code{b} shape parameter in \code{\link{dbeta}}}

\item{n}{specifies the number of Bernoulli trials (\code{size} in
\code{\link{dbinom}})}
}
\description{
Loss functions are minimized during model training. \code{loss} objects contain
 a \code{loss} function as well as a \code{grad} function, specifying the gradient.
 \code{loss} classes like the negative binomial can also store parameters that can be
 updated during training.

\code{bernoulliLoss}:
cross-entropy for 0-1 data. Equal to
  \code{-(y * log(yhat) + (1 - y) * log(1 - yhat))}

\code{bernoulliRegLoss}: cross-entropy loss, regularized by a
  beta-distributed prior.
Note that \code{a} and \code{b} are not

\code{poissonLoss}: loss based on the Poisson likelihood.
  See \code{\link{dpois}}

\code{nbLoss}: loss based on the negative binomial likelihood
  See \code{\link{dnbinom}}

\code{squaredLoss}: Squared error, for linear models

\code{binomialLoss}: loss for binomial responses.
}

